{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "with open(\"/home/seongilpark/rag/GSM-IC_2step.json\", \"r\") as f:\n",
    "    df = pd.DataFrame(json.load(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(df[\"original_question\"].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34140"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"new_question\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_template = 'Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \\n\\nText by User: [ORIGINAL INPUT PROMPT]'\n",
    "# [ORIGINAL INPUT PROMPT] : is the placeholder for the original input prompt. Please do not remove it.\n",
    "unbiased_template = '[INPUT CONTEXT]\\n\\nAnswer in an unbiased way.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(input_text):\n",
    "    template = \"<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\\n\\n[INPUT] [/INST]\"\n",
    "    return template.replace(\"[INPUT]\", input_text)\n",
    "\n",
    "def S2A(question: str, tokenizer, model):\n",
    "    s2a_prompt = make_prompt(relevant_template.replace(\"[ORIGINAL INPUT PROMPT]\", question))\n",
    "    print(s2a_prompt)\n",
    "    encoded_prompt = tokenizer.encode(s2a_prompt, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        first = model.generate(\n",
    "        input_ids=encoded_prompt,\n",
    "        max_new_tokens=300,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "        )\n",
    "    pred = tokenizer.decode(first[0], skip_special_tokens=True).split(\"[/INST]\")[-1].strip()\n",
    "    print(pred)\n",
    "    real_prompt = make_prompt(unbiased_template.replace(\"[INPUT CONTEXT]\", pred))\n",
    "    print(real_prompt)\n",
    "    encoded_prompt = tokenizer.encode(real_prompt, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        second = model.generate(\n",
    "        input_ids=encoded_prompt,\n",
    "        max_new_tokens=300,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9\n",
    "        )\n",
    "    real_pred = tokenizer.decode(second[0], skip_special_tokens=True).split(\"[/INST]\")[-1].strip()\n",
    "    return real_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebad2e3e598844e692b35bd561e354b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=\"meta-llama/Llama-2-13b-chat-hf\",\n",
    "                                             trust_remote_code=True,\n",
    "                                             torch_dtype = torch.bfloat16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             use_flash_attention_2=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-13b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd10555741ae4f3c84af0ed75ae1cb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: Edmund owns a gift wrapping shop, he uses 18 inches of gift wrapper per gift box. Edmund's neighbor is 500 years old. If Edmund has 90 inches of gift wrapper per day, how many gift boxes will he be able to wrap every 3 days? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "Edmund owns a gift wrapping shop, he uses 18 inches of gift wrapper per gift box.\n",
      "\n",
      "Detailed question:\n",
      "\n",
      "If Edmund has 90 inches of gift wrapper per day, how many gift boxes will he be able to wrap every 3 days?\n",
      "\n",
      "The context text provides information about Edmund's gift wrapping shop and the amount of gift wrapper he uses per gift box. This information is relevant to the question because it helps to determine how much gift wrapper Edmund has available to use each day. The detailed question asks how many gift boxes Edmund will be able to wrap in a specific time period (three days).\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "Edmund owns a gift wrapping shop, he uses 18 inches of gift wrapper per gift box.\n",
      "\n",
      "Detailed question:\n",
      "\n",
      "If Edmund has 90 inches of gift wrapper per day, how many gift boxes will he be able to wrap every 3 days?\n",
      "\n",
      "The context text provides information about Edmund's gift wrapping shop and the amount of gift wrapper he uses per gift box. This information is relevant to the question because it helps to determine how much gift wrapper Edmund has available to use each day. The detailed question asks how many gift boxes Edmund will be able to wrap in a specific time period (three days).\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: In Zeoland the fine for speeding is $16 for each mile per hour the driver is traveling over the posted speed limit. In Zeoland, Jed was fined $256 for speeding on a road with a posted speed limit of 50 mph. In Neoland, the fine for speeding is $24 for each mile per hour; and Jack was fined for $72. Jed was fined for traveling at what speed in miles per hour? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "In Zeoland, the fine for speeding is $16 for each mile per hour the driver is traveling over the posted speed limit. In Zeoland, Jed was fined $256 for speeding on a road with a posted speed limit of 50 mph. In Neoland, the fine for speeding is $24 for each mile per hour; and Jack was fined for $72.\n",
      "\n",
      "Detailed question:\n",
      "\n",
      "What was Jed's speed in miles per hour?\n",
      "\n",
      "Based on the information provided, we know that Jed was fined $256 for speeding in Zeoland, where the fine is $16 for each mile per hour over the posted speed limit. The posted speed limit was 50 mph, so we can calculate Jed's speed as follows:\n",
      "\n",
      "$256 = 16 x (Jed's speed in mph + 50)\n",
      "\n",
      "Solving for Jed's speed, we get:\n",
      "\n",
      "Jed's speed = 50 + (256 / 16)\n",
      "= 50 + 16\n",
      "= 66 mph\n",
      "\n",
      "There\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "In Zeoland, the fine for speeding is $16 for each mile per hour the driver is traveling over the posted speed limit. In Zeoland, Jed was fined $256 for speeding on a road with a posted speed limit of 50 mph. In Neoland, the fine for speeding is $24 for each mile per hour; and Jack was fined for $72.\n",
      "\n",
      "Detailed question:\n",
      "\n",
      "What was Jed's speed in miles per hour?\n",
      "\n",
      "Based on the information provided, we know that Jed was fined $256 for speeding in Zeoland, where the fine is $16 for each mile per hour over the posted speed limit. The posted speed limit was 50 mph, so we can calculate Jed's speed as follows:\n",
      "\n",
      "$256 = 16 x (Jed's speed in mph + 50)\n",
      "\n",
      "Solving for Jed's speed, we get:\n",
      "\n",
      "Jed's speed = 50 + (256 / 16)\n",
      "= 50 + 16\n",
      "= 66 mph\n",
      "\n",
      "There\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: In Zeoland the fine for speeding is $16 for each mile per hour the driver is traveling over the posted speed limit. In Zeoland, Jed was fined $256 for speeding on a road with a posted speed limit of 50 mph. Tom droved 2000 miles per hour, and was not fined in another city. Jed was fined for traveling at what speed in miles per hour? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information extracted and labeled:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "* In Zeoland, the fine for speeding is $16 for each mile per hour the driver is traveling over the posted speed limit.\n",
      "* Jed was fined $256 for speeding on a road with a posted speed limit of 50 mph.\n",
      "* Tom drove 2000 miles per hour, but was not fined in another city.\n",
      "\n",
      "Detailed question:\n",
      "\n",
      "What speed was Jed traveling at in miles per hour to receive a fine of $256 in Zeoland?\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information extracted and labeled:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "* In Zeoland, the fine for speeding is $16 for each mile per hour the driver is traveling over the posted speed limit.\n",
      "* Jed was fined $256 for speeding on a road with a posted speed limit of 50 mph.\n",
      "* Tom drove 2000 miles per hour, but was not fined in another city.\n",
      "\n",
      "Detailed question:\n",
      "\n",
      "What speed was Jed traveling at in miles per hour to receive a fine of $256 in Zeoland?\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: Each wall of a 3 sided shower has 8 tiles running the width of the wall and 20 tiles running the height of the wall. The shoe size of Jack is 5000. How many tiles are in the shower? [/INST]\n",
      "Sure! Here's the extracted text related to the question:\n",
      "\n",
      "Context text related to the question: Each wall of a 3-sided shower has 8 tiles running the width of the wall and 20 tiles running the height of the wall.\n",
      "\n",
      "Detailed question: How many tiles are in the shower?\n",
      "\n",
      "The user is asking for the total number of tiles in the shower, given the dimensions of each wall and the shoe size of Jack.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure! Here's the extracted text related to the question:\n",
      "\n",
      "Context text related to the question: Each wall of a 3-sided shower has 8 tiles running the width of the wall and 20 tiles running the height of the wall.\n",
      "\n",
      "Detailed question: How many tiles are in the shower?\n",
      "\n",
      "The user is asking for the total number of tiles in the shower, given the dimensions of each wall and the shoe size of Jack.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: Jeanne wants to ride the Ferris wheel, the roller coaster, and the bumper cars. The Ferris wheel costs 5 tickets, the roller coaster costs 4 tickets and the bumper cars cost 4 tickets. Jeanne has 5 tickets. The height of Tom is 20000 feet. How many more tickets should Jeanne buy? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Jeanne wants to ride the Ferris wheel, the roller coaster, and the bumper cars. The Ferris wheel costs 5 tickets, the roller coaster costs 4 tickets, and the bumper cars cost 4 tickets. Jeanne has 5 tickets.\n",
      "\n",
      "Detailed question: How many more tickets should Jeanne buy?\n",
      "\n",
      "The context text provides information about the rides Jeanne wants to go on, the cost of each ride, and the number of tickets Jeanne has. This information is useful for determining how many more tickets Jeanne should buy. The detailed question is clear and specific, asking for the exact number of tickets Jeanne should purchase.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Jeanne wants to ride the Ferris wheel, the roller coaster, and the bumper cars. The Ferris wheel costs 5 tickets, the roller coaster costs 4 tickets, and the bumper cars cost 4 tickets. Jeanne has 5 tickets.\n",
      "\n",
      "Detailed question: How many more tickets should Jeanne buy?\n",
      "\n",
      "The context text provides information about the rides Jeanne wants to go on, the cost of each ride, and the number of tickets Jeanne has. This information is useful for determining how many more tickets Jeanne should buy. The detailed question is clear and specific, asking for the exact number of tickets Jeanne should purchase.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: Charles is moving from Springfield, which has 482,653 people, to Greenville, which has 119,666 fewer people. The school of Charles' neighbor has 174285 students. What is the total population of Springfield and Greenville? [/INST]\n",
      "Sure! Here's the extracted text:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Charles is moving from Springfield, which has 482,653 people, to Greenville, which has 119,666 fewer people. The school of Charles' neighbor has 174285 students.\n",
      "\n",
      "Detailed question: What is the total population of Springfield and Greenville?\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure! Here's the extracted text:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Charles is moving from Springfield, which has 482,653 people, to Greenville, which has 119,666 fewer people. The school of Charles' neighbor has 174285 students.\n",
      "\n",
      "Detailed question: What is the total population of Springfield and Greenville?\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: Megan is an actress. She was the lead actress in 80% of her work. In total, Megan participated in 100 plays. Megan's brother bought 300 tomatoes from the grocery store. How many times Megan was not the lead actress? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Megan is an actress. She was the lead actress in 80% of her work. In total, Megan participated in 100 plays.\n",
      "\n",
      "Detailed question: How many times Megan was not the lead actress?\n",
      "\n",
      "Based on the context, the question is asking for the number of times Megan was not the lead actress in the 100 plays she participated in.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Megan is an actress. She was the lead actress in 80% of her work. In total, Megan participated in 100 plays.\n",
      "\n",
      "Detailed question: How many times Megan was not the lead actress?\n",
      "\n",
      "Based on the context, the question is asking for the number of times Megan was not the lead actress in the 100 plays she participated in.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: Each wall of a 3 sided shower has 8 tiles running the width of the wall and 20 tiles running the height of the wall. James' neighbor is 100 years old. How many tiles are in the shower? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information extracted and labeled:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "* Each wall of a 3-sided shower has 8 tiles running the width of the wall.\n",
      "* Each wall of a 3-sided shower has 20 tiles running the height of the wall.\n",
      "* James' neighbor is 100 years old.\n",
      "\n",
      "Detailed question: How many tiles are in the shower?\n",
      "\n",
      "Based on the information provided, the shower has 8 tiles running the width of each wall and 20 tiles running the height of each wall. To find the total number of tiles in the shower, we need to multiply the number of tiles running the width of each wall by the number of walls (3) and then multiply that result by the number of tiles running the height of each wall.\n",
      "\n",
      "So, the total number of tiles in the shower is:\n",
      "\n",
      "8 tiles/wall x 3 walls = 24 tiles/wall\n",
      "24 tiles/wall x 20 tiles/height = 480 tiles\n",
      "\n",
      "Therefore, there are 480 tiles in the shower.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information extracted and labeled:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "* Each wall of a 3-sided shower has 8 tiles running the width of the wall.\n",
      "* Each wall of a 3-sided shower has 20 tiles running the height of the wall.\n",
      "* James' neighbor is 100 years old.\n",
      "\n",
      "Detailed question: How many tiles are in the shower?\n",
      "\n",
      "Based on the information provided, the shower has 8 tiles running the width of each wall and 20 tiles running the height of each wall. To find the total number of tiles in the shower, we need to multiply the number of tiles running the width of each wall by the number of walls (3) and then multiply that result by the number of tiles running the height of each wall.\n",
      "\n",
      "So, the total number of tiles in the shower is:\n",
      "\n",
      "8 tiles/wall x 3 walls = 24 tiles/wall\n",
      "24 tiles/wall x 20 tiles/height = 480 tiles\n",
      "\n",
      "Therefore, there are 480 tiles in the shower.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: It was time for Kelly to harvest her carrots that she had planted in three different beds. In the first bed she pulled out 55 carrots. In the second bed she pulled out 101 carrots and in the third bed she pulled out 78 carrots. She found that 6 carrots weighed one pound. Kelly's neighbor harvested 3 more potatoes last year. How many pounds of carrots did Kelly harvest? [/INST]\n",
      "Sure! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Kelly had planted carrots in three different beds, and she wanted to know how many pounds of carrots she had harvested. She knew that 6 carrots weighed one pound, and she had pulled out 55 carrots from the first bed, 101 carrots from the second bed, and 78 carrots from the third bed.\n",
      "\n",
      "Detailed question: How many pounds of carrots did Kelly harvest?\n",
      "\n",
      "With this context, I can provide an accurate answer to the user's question.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Kelly had planted carrots in three different beds, and she wanted to know how many pounds of carrots she had harvested. She knew that 6 carrots weighed one pound, and she had pulled out 55 carrots from the first bed, 101 carrots from the second bed, and 78 carrots from the third bed.\n",
      "\n",
      "Detailed question: How many pounds of carrots did Kelly harvest?\n",
      "\n",
      "With this context, I can provide an accurate answer to the user's question.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: Libby has 160 quarters in her piggy bank. She has to pay $35 to replace her sister’s dress that she borrowed and ruined. The salary of Libby's neighbor is $100 more than Libby per month. After replacing the dress, how many quarters will Libby have left? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Libby has 160 quarters in her piggy bank. She has to pay $35 to replace her sister's dress that she borrowed and ruined. The salary of Libby's neighbor is $100 more than Libby per month.\n",
      "\n",
      "Detailed question: After replacing the dress, how many quarters will Libby have left?\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Libby has 160 quarters in her piggy bank. She has to pay $35 to replace her sister's dress that she borrowed and ruined. The salary of Libby's neighbor is $100 more than Libby per month.\n",
      "\n",
      "Detailed question: After replacing the dress, how many quarters will Libby have left?\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: Papi Calot prepared his garden to plant potatoes. He planned to plant 7 rows of 18 plants each. But he still has a bit of room left, so he’s thinking about adding 15 additional potato plants. Papi Calot's mother has 2 children. How many plants does Papi Calot have to buy? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Papi Calot prepared his garden to plant potatoes. He planned to plant 7 rows of 18 plants each. But he still has a bit of room left, so he's thinking about adding 15 additional potato plants.\n",
      "\n",
      "Detailed question: How many plants does Papi Calot have to buy?\n",
      "\n",
      "The context text provides information about Papi Calot's garden and his plan to plant potatoes. It also mentions that he has some extra space left and is considering adding more plants. The detailed question is \"How many plants does Papi Calot have to buy?\" which is clearly related to the context text and can be answered based on the information provided.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, broken down into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Papi Calot prepared his garden to plant potatoes. He planned to plant 7 rows of 18 plants each. But he still has a bit of room left, so he's thinking about adding 15 additional potato plants.\n",
      "\n",
      "Detailed question: How many plants does Papi Calot have to buy?\n",
      "\n",
      "The context text provides information about Papi Calot's garden and his plan to plant potatoes. It also mentions that he has some extra space left and is considering adding more plants. The detailed question is \"How many plants does Papi Calot have to buy?\" which is clearly related to the context text and can be answered based on the information provided.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: Lizzy has to ship 540 pounds of fish that are packed into 30-pound crates. Lizzy's sister ate 10 pounds of lobster yesterday. If the shipping cost of each crate is $1.5, how much will Lizzy pay for the shipment? [/INST]\n",
      "Sure! Here is the text you provided, with the relevant information separated into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Lizzy has to ship 540 pounds of fish that are packed into 30-pound crates.\n",
      "\n",
      "Detailed question: If the shipping cost of each crate is $1.5, how much will Lizzy pay for the shipment?\n",
      "\n",
      "Using this context, I can provide an accurate answer to the question.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure! Here is the text you provided, with the relevant information separated into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Lizzy has to ship 540 pounds of fish that are packed into 30-pound crates.\n",
      "\n",
      "Detailed question: If the shipping cost of each crate is $1.5, how much will Lizzy pay for the shipment?\n",
      "\n",
      "Using this context, I can provide an accurate answer to the question.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: As soon as you enter the taxi, you pay a ride fee of $2. Michelle rode a taxi from her office to her home, which constitutes 4 miles. Michelle's brother rode a bike to the office for 50000 miles. If the taxi charge per mile is $2.5, how much did pay Michelle pay in total for her ride? [/INST]\n",
      "Sure! Here's the extracted text related to the question:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Michelle rode a taxi from her office to her home, which constitutes 4 miles.\n",
      "\n",
      "Detailed question:\n",
      "If the taxi charge per mile is $2.5, how much did Michelle pay in total for her ride?\n",
      "\n",
      "Note that the unrelated sentence \"Michelle's brother rode a bike to the office for 50000 miles\" is not included in the extracted text.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure! Here's the extracted text related to the question:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Michelle rode a taxi from her office to her home, which constitutes 4 miles.\n",
      "\n",
      "Detailed question:\n",
      "If the taxi charge per mile is $2.5, how much did Michelle pay in total for her ride?\n",
      "\n",
      "Note that the unrelated sentence \"Michelle's brother rode a bike to the office for 50000 miles\" is not included in the extracted text.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: James hurts himself and decides to go to his primary care doctor. His primary care doctor charges $300 for the visit and James's insurance covers 80%. James' neighbor earns $200000 per month. What is James's out-of-pocket cost for his doctor appointment? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information separated into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "James hurts himself and decides to go to his primary care doctor. His primary care doctor charges $300 for the visit and James's insurance covers 80%.\n",
      "\n",
      "Detailed question:\n",
      "\n",
      "What is James's out-of-pocket cost for his doctor appointment?\n",
      "\n",
      "Based on the information provided, James's out-of-pocket cost for his doctor appointment would be $60 (20% of $300, since his insurance covers 80%).\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information separated into two categories:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "James hurts himself and decides to go to his primary care doctor. His primary care doctor charges $300 for the visit and James's insurance covers 80%.\n",
      "\n",
      "Detailed question:\n",
      "\n",
      "What is James's out-of-pocket cost for his doctor appointment?\n",
      "\n",
      "Based on the information provided, James's out-of-pocket cost for his doctor appointment would be $60 (20% of $300, since his insurance covers 80%).\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: For football season, Zachary wants to buy a new football, a pair of shorts, and a pair of football shoes. The football costs $3.75, the shorts cost $2.40, and the shoes cost $11.85. Zachary has $10. The height of Mary is 100000 feet. How much more money does Zachary need? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information extracted and labeled:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "Zachary wants to buy a new football, a pair of shorts, and a pair of football shoes. The football costs $3.75, the shorts cost $2.40, and the shoes cost $11.85. Zachary has $10.\n",
      "\n",
      "Detailed question: How much more money does Zachary need?\n",
      "\n",
      "The user is asking how much more money Zachary needs to buy the items he wants, given that he has $10 and the items cost a total of $3.75 + $2.40 + $11.85 = $17.90.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information extracted and labeled:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "Zachary wants to buy a new football, a pair of shorts, and a pair of football shoes. The football costs $3.75, the shorts cost $2.40, and the shoes cost $11.85. Zachary has $10.\n",
      "\n",
      "Detailed question: How much more money does Zachary need?\n",
      "\n",
      "The user is asking how much more money Zachary needs to buy the items he wants, given that he has $10 and the items cost a total of $3.75 + $2.40 + $11.85 = $17.90.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: My brother and I have thirty minutes to go to school, without being late. It takes us 15 minutes to arrive at the school gate, and another 6 minutes to get to the school building. my brother is 500 years old. How much time do we have to get to our room, without being late? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information extracted and labeled:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "My brother and I have thirty minutes to go to school, without being late. It takes us 15 minutes to arrive at the school gate, and another 6 minutes to get to the school building.\n",
      "\n",
      "Detailed question:\n",
      "\n",
      "How much time do we have to get to our room, without being late?\n",
      "\n",
      "In this case, the context text related to the question includes all of the information about the time available and the journey to school, while the detailed question is \"How much time do we have to get to our room, without being late?\"\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information extracted and labeled:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "My brother and I have thirty minutes to go to school, without being late. It takes us 15 minutes to arrive at the school gate, and another 6 minutes to get to the school building.\n",
      "\n",
      "Detailed question:\n",
      "\n",
      "How much time do we have to get to our room, without being late?\n",
      "\n",
      "In this case, the context text related to the question includes all of the information about the time available and the journey to school, while the detailed question is \"How much time do we have to get to our room, without being late?\"\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: Mary has 3 times as much candy as Megan. Mary then adds 10 more pieces of candy to her collection. The shoe size of Mary's father is 8. If Megan has 5 pieces of candy, how many does Mary have in total? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information extracted and labeled:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Mary has 3 times as much candy as Megan. Mary then adds 10 more pieces of candy to her collection. The shoe size of Mary's father is 8.\n",
      "\n",
      "Detailed question: If Megan has 5 pieces of candy, how many does Mary have in total?\n",
      "\n",
      "Using this context, I can provide an accurate answer to the user's question.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information extracted and labeled:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Mary has 3 times as much candy as Megan. Mary then adds 10 more pieces of candy to her collection. The shoe size of Mary's father is 8.\n",
      "\n",
      "Detailed question: If Megan has 5 pieces of candy, how many does Mary have in total?\n",
      "\n",
      "Using this context, I can provide an accurate answer to the user's question.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: My brother and I have thirty minutes to go to school, without being late. It takes us 15 minutes to arrive at the school gate, and another 6 minutes to get to the school building. The height of my neighbor is 30 feet. How much time do we have to get to our room, without being late? [/INST]\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information extracted and labeled:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "* My brother and I have thirty minutes to go to school, without being late.\n",
      "* It takes us 15 minutes to arrive at the school gate, and another 6 minutes to get to the school building.\n",
      "* The height of my neighbor is 30 feet.\n",
      "\n",
      "Detailed question: How much time do we have to get to our room, without being late?\n",
      "\n",
      "The context text related to the question includes all the information about the time available, the time it takes to arrive at the school, and the height of the neighbor. This information is useful for providing an accurate answer to the question. The detailed question is \"How much time do we have to get to our room, without being late?\"\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure, I'd be happy to help! Here's the text you provided, with the relevant information extracted and labeled:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "\n",
      "* My brother and I have thirty minutes to go to school, without being late.\n",
      "* It takes us 15 minutes to arrive at the school gate, and another 6 minutes to get to the school building.\n",
      "* The height of my neighbor is 30 feet.\n",
      "\n",
      "Detailed question: How much time do we have to get to our room, without being late?\n",
      "\n",
      "The context text related to the question includes all the information about the time available, the time it takes to arrive at the school, and the height of the neighbor. This information is useful for providing an accurate answer to the question. The detailed question is \"How much time do we have to get to our room, without being late?\"\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: Each wall of a 3 sided shower has 8 tiles running the width of the wall and 20 tiles running the height of the wall. Ada drew 200 flowers on each tile. How many tiles are in the shower? [/INST]\n",
      "Sure! Here's the extracted text related to the question:\n",
      "\n",
      "Context text related to the question:\n",
      "\n",
      "Each wall of a 3-sided shower has 8 tiles running the width of the wall and 20 tiles running the height of the wall.\n",
      "\n",
      "Detailed question:\n",
      "\n",
      "How many tiles are in the shower?\n",
      "\n",
      "Note that the user is asking about the total number of tiles in the shower, which can be calculated by multiplying the number of tiles running the width and height of each wall.\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure! Here's the extracted text related to the question:\n",
      "\n",
      "Context text related to the question:\n",
      "\n",
      "Each wall of a 3-sided shower has 8 tiles running the width of the wall and 20 tiles running the height of the wall.\n",
      "\n",
      "Detailed question:\n",
      "\n",
      "How many tiles are in the shower?\n",
      "\n",
      "Note that the user is asking about the total number of tiles in the shower, which can be calculated by multiplying the number of tiles running the width and height of each wall.\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Given the following text by a user, extract the part that is related and useful, so that using that text alone would be good context for providing an accurate and correct answer to the question portion of the text. Please include the actual question or query that the user is asking. Separate this into two categories labeled with ”Context text related to the question (includes all content except unrelated sentences):” and ”Detailed question:”.Do not use list. \n",
      "\n",
      "Text by User: Genevieve picked some cherries from the supermarket shelves that cost $8 per kilogram. When Genevieve reached the checkout counter, she realized she was $400 short of the total price and her friend Clarice chipped in. Clarice's neighbor bought 10000 kilograms of strawberries yesterday. If Genevieve had $1600 on her, how many kilograms of cherries did she buy? [/INST]\n",
      "Sure! Here is the extracted text:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Genevieve picked some cherries from the supermarket shelves that cost $8 per kilogram. She realized she was $400 short of the total price and her friend Clarice chipped in. Clarice's neighbor bought 10000 kilograms of strawberries yesterday.\n",
      "\n",
      "Detailed question: How many kilograms of cherries did Genevieve buy if she had $1600 on her?\n",
      "<s>[INST] <<SYS>You are a helpful assitant.<</SYS>>>\n",
      "\n",
      "Sure! Here is the extracted text:\n",
      "\n",
      "Context text related to the question (includes all content except unrelated sentences):\n",
      "Genevieve picked some cherries from the supermarket shelves that cost $8 per kilogram. She realized she was $400 short of the total price and her friend Clarice chipped in. Clarice's neighbor bought 10000 kilograms of strawberries yesterday.\n",
      "\n",
      "Detailed question: How many kilograms of cherries did Genevieve buy if she had $1600 on her?\n",
      "\n",
      "Answer in an unbiased way. [/INST]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "preds, answers = [], []\n",
    "for row_ in tqdm(sample_df.iterrows()):\n",
    "    row = row_[1]\n",
    "    q, a = row[\"new_question\"], row[\"answer\"]\n",
    "    pred = S2A(q, tokenizer, model)\n",
    "    preds.append(pred)\n",
    "    answers.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_match_acc(answer: str, pred: str):\n",
    "    answer = answer.lower().strip()\n",
    "    pred = pred.lower().strip()\n",
    "    if answer in pred:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1a1d1b1a1s1d1 1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for p, a in zip(preds, answers):\n",
    "    acc = cal_match_acc(a, p)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.sample(100)\n",
    "questions, ctxs, answers = sample_df[\"question\"].tolist(), sample_df[\"context\"].tolist(), sample_df[\"answers\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c120dfefab74aac976bd9f8b9e94d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "prompts, preds, is_answer = [], [], []\n",
    "for q, c, a in zip(tqdm(questions), ctxs, answers):\n",
    "    prompt = make_prompt(c, q)\n",
    "    prompts.append(prompt)\n",
    "    encoded_prompt = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        output_sequences = model.generate(\n",
    "        input_ids=encoded_prompt,\n",
    "        max_new_tokens=200,\n",
    "        )\n",
    "    pred = tokenizer.decode(output_sequences[0], skip_special_tokens=True).split(\"[/INST]\")[-1].strip()\n",
    "    is_correct= any([ans.lower() in pred.lower() for ans in a])\n",
    "    print(is_correct)\n",
    "    is_answer.append(is_correct)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers: {'text': ['(/ˈfrɛznoʊ/ FREZ-noh)', 'FREZ-noh', 'FREZ-noh'], 'answer_start': [7, 19, 19]}\n",
      "Pred: Sure thing! Based on the context, the correct pronunciation of Fresno is /ˈfrɛznoʊ/ FREZ-noh.\n",
      "Answers: {'text': ['Numerical models', 'Numerical', 'Numerical models'], 'answer_start': [448, 448, 448]}\n",
      "Pred: Based on the context, numerical models of orogenic wedges are more sophisticated than analog models. Numerical models can include patterns of erosion and uplift, and can simulate the relationship between erosion and the shape of the mountain range, which is not possible with analog models. Additionally, numerical models can provide more detailed information about pathways for metamorphism through pressure, temperature, space, and time, making them more sophisticated.\n",
      "Answers: {'text': ['mainline Protestant denomination', 'Protestant denomination', 'mainline Protestant denomination'], 'answer_start': [207, 216, 207]}\n",
      "Pred: Sure! Based on the context, the answer to the question \"In the United States, the UMC ranks as the largest ______.\" is:\n",
      "\n",
      "Largest mainline Protestant denomination.\n",
      "Answers: {'text': ['Sentences by Peter Lombard', 'Sentences', 'Sentences by Peter Lombard'], 'answer_start': [271, 271, 271]}\n",
      "Pred: Based on the context, Luther's degree in 1509 concerned a bachelor's degree in the Sentences by Peter Lombard.\n",
      "Answers: {'text': ['7,000 doctors', '7,000', '7,000'], 'answer_start': [382, 382, 382]}\n",
      "Pred: Based on the context, there were 7,000 doctors in Kenya in 2011.\n",
      "Answers: {'text': ['the same', 'a Galilean transformation', 'Galilean transformation', 'the laws of physics are the same in every inertial frame of reference', 'the same in every inertial frame of reference'], 'answer_start': [1065, 1146, 1148, 1041, 1065]}\n",
      "Pred: Based on the context, the laws of physics of Galileo, in reference to objects in motion and rest, are the Rosetta laws of physics. These laws state that the laws of physics are the same in every inertial frame of reference, that is, in all frames related by a Galilean transformation. This means that it is impossible to determine which object is \"in motion\" and which object is \"at rest\" in a system where objects are moving with different velocities.\n",
      "Answers: {'text': ['the Metropolitan Police Authority', 'Metropolitan Police Authority', 'the Metropolitan Police Authority'], 'answer_start': [387, 391, 387]}\n",
      "Pred: Based on the context, the answer to the question is:\n",
      "\n",
      "Metropolitan Police Authority.\n",
      "Answers: {'text': ['60', '60', 'all'], 'answer_start': [618, 618, 65]}\n",
      "Pred: Based on the context, about 60 Chinese schools became National Type schools as a result of the compromise.\n",
      "Answers: {'text': ['1979', '1979', '1979', '1979'], 'answer_start': [1184, 1184, 1184, 1184]}\n",
      "Pred: Based on the context, the answer to the question \"When did the first direct elections take place?\" is:\n",
      "\n",
      "1979.\n",
      "Answers: {'text': ['$414 million', '$414 million', '$414 million'], 'answer_start': [449, 449, 449]}\n",
      "Pred: Based on the context, the total of Grants awarded from Harvard in 2009 was $414 million.\n",
      "Answers: {'text': ['force', 'force', 'the concept of force', 'the concept of force', 'force', 'force'], 'answer_start': [46, 46, 31, 31, 46, 46]}\n",
      "Pred: Based on the context, the concept that philosophers in antiquity used to study simple machines was \"force.\"\n",
      "Answers: {'text': ['half-hourly', 'half-hourly', 'half-hourly'], 'answer_start': [51, 51, 51]}\n",
      "Pred: Sure, I'd be happy to help! Based on the context you provided, trains journey to King's Cross half hourly.\n",
      "Answers: {'text': [\"Levi's Stadium\", \"Levi's Stadium\", \"Levi's Stadium in the San Francisco Bay Area at Santa Clara\"], 'answer_start': [355, 355, 355]}\n",
      "Pred: Sure, I'd be happy to help! Based on the context, the answer to your question is:\n",
      "\n",
      "Super Bowl 50 took place at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\n",
      "Answers: {'text': ['(p − 1)! + 1', '(p − 1)! + 1', '(p − 1)! + 1', '(p − 1)! + 1', '(p − 1)! + 1'], 'answer_start': [495, 495, 495, 495, 495]}\n",
      "Pred: According to Wilson's theorem, the factorial (p - 1)! + 1 must be divisible by p if some integer p > 1 is to be considered prime.\n",
      "Answers: {'text': ['John Madejski Garden', 'the John Madejski Garden', 'John Madejski Garden'], 'answer_start': [66, 62, 66]}\n",
      "Pred: Sure! Based on the context, the redesigned central garden opened in 2005 with the new moniker of the John Madejski Garden.\n",
      "Answers: {'text': ['under the temporal sovereign', 'church government under the temporal sovereign', 'church government under the temporal sovereign'], 'answer_start': [659, 641, 641]}\n",
      "Pred: Based on the context, the unintended development that the relationship with the elector had on church government was a move towards a church government under the temporal sovereign, as stated by Luther's biographer Martin Brecht.\n",
      "Answers: {'text': ['Anne Sweeney', 'Anne Sweeney', 'Anne Sweeney'], 'answer_start': [644, 644, 644]}\n",
      "Pred: Based on the context, the answer to the question is:\n",
      "\n",
      "Anne Sweeney.\n",
      "\n",
      "According to the text, Anne Sweeney was named president of ABC parent Disney–ABC Television Group in April 2004.\n",
      "Answers: {'text': ['at least one advanced course every three years', 'complete the basic course and one advanced lay servant course,', 'one advanced course every three years'], 'answer_start': [1097, 896, 1106]}\n",
      "Pred: Based on the context, a local lay servant must complete one basic course and reapply annually. There is no mention of a specific number of courses that a local lay servant must take.\n",
      "Answers: {'text': ['destroyed', 'destroyed', 'destroyed'], 'answer_start': [472, 472, 472]}\n",
      "Pred: Based on the context, in 2005, the Doctor thought that his home planet, Gallifrey, had been destroyed. This is stated in the serial \"The Empty Child\" when Dr. Constantine says, \"Before the war even began, I was a father and a grandfather. Now I am neither.\" The Doctor responds with, \"Yeah, I know the feeling.\"\n",
      "Answers: {'text': ['Mycobacterium tuberculosis', 'Mycobacterium tuberculosis', 'Mycobacterium tuberculosis'], 'answer_start': [548, 548, 548]}\n",
      "Pred: Based on the context, the answer to the question is: Mycobacterium tuberculosis.\n",
      "Answers: {'text': ['Gamal Abdul Nasser', 'Gamal Abdul Nasser', 'Gamal Abdul Nasser'], 'answer_start': [435, 435, 435]}\n",
      "Pred: Based on the context, the Egyptian president who jailed thousands of members of the Brotherhood is Gamal Abdul Nasser.\n",
      "Answers: {'text': ['broken arm', 'a broken arm', 'broken arm'], 'answer_start': [145, 143, 145]}\n",
      "Pred: Based on the context, the answer to the question is:\n",
      "\n",
      "Thomas Davis suffered a broken arm during the playoff games.\n",
      "Answers: {'text': ['Polonez', '125p', 'Polonez'], 'answer_start': [235, 196, 235]}\n",
      "Pred: Based on the context, the car licensed by the FSO Car Factory and built in Egypt is the FSO 125p.\n",
      "Answers: {'text': ['confirmed', 'confirmed', 'confirmed'], 'answer_start': [235, 235, 235]}\n",
      "Pred: Based on the context, Luther responded by requesting time to think about the answer to the second question and prayed before giving his response the next day.\n",
      "Answers: {'text': ['conservative', 'strict, conservative', 'strict, conservative'], 'answer_start': [69, 61, 61]}\n",
      "Pred: Based on the context, Salafism promotes a strict, conservative interpretation of Islam that is closely tied to the Saudi tradition and preaches a deep hatred of infidels, including Shia and other non-Wahhabi Muslims, and views democracy as responsible for all the horrible wars of the 20th century.\n",
      "Answers: {'text': ['Anglo-Saxons', 'the Anglo-Saxons', 'Anglo-Saxons'], 'answer_start': [161, 157, 161]}\n",
      "Pred: Based on the context, the ruling class ahead of the Normans were the Anglo-Saxons.\n",
      "Answers: {'text': ['the Atlantic', 'the Atlantic', 'Atlantic'], 'answer_start': [179, 179, 516]}\n",
      "Pred: Based on the context, water to the east of the Amazon drainage basin flowed towards the Atlantic Ocean.\n",
      "Answers: {'text': ['28', '28', '28', '28'], 'answer_start': [707, 707, 707, 707]}\n",
      "Pred: Based on the context, the answer to the question \"How many total judges are there in the EU?\" is:\n",
      "\n",
      "78 total judges in the EU, as there are 28 judges from each member state, as stated in the Treaty on European Union article 19(2).\n",
      "Answers: {'text': ['More than 1 million', 'More than 1 million', '1 million'], 'answer_start': [292, 292, 302]}\n",
      "Pred: Based on the context, it is likely that a large number of people will visit Justin Herman Plaza during the week of the Super Bowl. The text states that \"more than 1 million people are expected to attend the festivities in San Francisco during Super Bowl Week.\" Additionally, the text mentions that \"Super Bowl City\" opened on January 30 at Justin Herman Plaza, featuring games and activities that will highlight the Bay Area's technology, culinary creations, and cultural diversity. Therefore, it is likely that a significant number of people will visit Justin Herman Plaza during the week of the Super Bowl.\n",
      "\n",
      "To answer your question, it is likely that more than 1 million people will visit Justin Herman Plaza during the week of the Super Bowl.\n",
      "Answers: {'text': ['New York City O&O WABC-TV and Philadelphia O&O WPVI-TV', 'New York City O&O WABC-TV and Philadelphia O&O WPVI-TV', 'WABC-TV and Philadelphia O&O WPVI-TV'], 'answer_start': [715, 715, 733]}\n",
      "Pred: Based on the context, the first local stations to offer streams of their programming on WATCH ABC were:\n",
      "\n",
      "1. New York City O&O WABC-TV\n",
      "2. Philadelphia O&O WPVI-TV\n",
      "\n",
      "These two stations were the first to offer streams of their programming on the service, with a free preview for non-subscribers through June 2013.\n",
      "Answers: {'text': ['no way contributes', 'in no way', 'in no way'], 'answer_start': [342, 339, 339]}\n",
      "Pred: Based on the context, Luther did not say that reason contributes to faith in the sense of providing evidence or proof for it. Instead, he believed that reason and faith are separate spheres of knowledge and that reason can be useful in understanding the external coherence of the Bible, but not in proving the internal truth of faith. As Lutheran scholarship has found, Luther believed in separating faith and reason in order to honor their different epistemological spheres. He valued both faith and reason and held them in dialectical partnership, rather than seeing them as antithetical.\n",
      "Answers: {'text': ['Von Miller', 'Von Miller', 'Miller'], 'answer_start': [306, 306, 310]}\n",
      "Pred: Sure thing! Based on the context, the answer to your question is:\n",
      "\n",
      "Von Miller.\n",
      "Answers: {'text': ['two', 'two', 'two'], 'answer_start': [286, 286, 286]}\n",
      "Pred: Based on the context, Setanta Sports was awarded two of the six Premier League packages that the English FA offered to broadcasters.\n",
      "Answers: {'text': ['Oswego', 'Oswego', 'Oswego', 'Oswego', 'Oswego'], 'answer_start': [493, 493, 493, 493, 493]}\n",
      "Pred: Based on the context, Montcalm slipped away to attack Oswego, which was left largely unprotected.\n",
      "Answers: {'text': ['constant pressure', 'constant pressure', 'constant pressure'], 'answer_start': [272, 272, 272]}\n",
      "Pred: Based on the context, isobaric means constant pressure.\n",
      "Answers: {'text': ['cut in half', 'cut in half', 'cut in half'], 'answer_start': [281, 281, 281]}\n",
      "Pred: Based on the context, the Trajan's Column replica was cut in half to fit under the ceiling.\n",
      "Answers: {'text': ['standard version', 'standard version', 'writing of an English translation'], 'answer_start': [190, 190, 302]}\n",
      "Pred: Based on the context, Luther's translation of the Bible promoted the development of a standard version of the German language.\n",
      "Answers: {'text': ['violence', 'violence', 'violence'], 'answer_start': [46, 46, 46]}\n",
      "Pred: Based on the context, al-Gama'a al-Islamiyya used violence to get its way. Specifically, the group employed tactics such as attempted assassinations of political figures, arson of video shops, and attempted takeovers of government buildings in its campaign against the Egyptian state in the 1990s.\n",
      "Answers: {'text': ['\"A Machine to End War\"', '\"A Machine to End War\"', 'A Machine to End War'], 'answer_start': [113, 113, 114]}\n",
      "Pred: Based on the context, the article that was published in 1937 is \"A Machine to End War\".\n",
      "Answers: {'text': ['1731', '1731'], 'answer_start': [197, 197]}\n",
      "Pred: Sure, I'd be happy to help! Based on the context, the Meissen Vulture in the V&A collection is dated to the year 1731.\n",
      "Answers: {'text': ['charity and good works', 'charity and good works', 'in charity and good works'], 'answer_start': [371, 371, 368]}\n",
      "Pred: Based on the context, man's justification in faith depends on both faith and good works. According to Roman Catholic theology, faith alone, whether fiduciary or dogmatic, cannot justify man; justification rather depends on such faith as is active in charity and good works (fides caritate formata).\n",
      "Answers: {'text': ['August 1992', 'August 1992', 'August 1992'], 'answer_start': [870, 870, 870]}\n",
      "Pred: Sure, I'd be happy to help! Based on the context, the revised Manual of Regulations for Private Schools was released in August 1992.\n",
      "Answers: {'text': ['The Knowledge School', 'The Knowledge School', 'The Knowledge School'], 'answer_start': [408, 408, 408]}\n",
      "Pred: Sure, I'd be happy to help! Based on the context, the English translation of Kunskapsskolan is \"The Knowledge School\".\n",
      "Answers: {'text': ['1935', 'In 1935', '1935'], 'answer_start': [3, 0, 3]}\n",
      "Pred: Based on the context, Tesla made these claims in 1910, not in 1935.\n",
      "Answers: {'text': ['Khwarezmid Empire', 'Khwarezmid', 'Khwarezmid Empire'], 'answer_start': [489, 489, 489]}\n",
      "Pred: Based on the context, the answer to your question is:\n",
      "\n",
      "The Khwarezmia (Khwarezmid Empire) bordered the Mongol Empire to the west in 1218.\n",
      "Answers: {'text': ['United States', 'United States', 'United States', 'United States'], 'answer_start': [311, 311, 311, 311]}\n",
      "Pred: Based on the context, corporal punishment is still allowed in the United States, specifically in the eastern part of Chicago.\n",
      "Answers: {'text': ['heart disease, chronic pain, and asthma', 'heart disease, chronic pain, and asthma', 'chronic pain'], 'answer_start': [573, 573, 588]}\n",
      "Pred: Based on the context, disruptions in sleep can lead to an increase in the following chronic conditions:\n",
      "\n",
      "1. Heart disease\n",
      "2. Chronic pain\n",
      "3. Asthma\n",
      "Answers: {'text': ['Coldplay', 'Coldplay', 'Coldplay'], 'answer_start': [194, 194, 194]}\n",
      "Pred: Based on the context, the answer to the question is:\n",
      "\n",
      "Coldplay.\n",
      "Answers: {'text': ['Besh Baliq, Almaliq, and Samarqand', 'Besh Baliq, Almaliq, and Samarqand', 'Bukhara'], 'answer_start': [361, 361, 211]}\n",
      "Pred: Based on the context, the answer to the question is:\n",
      "\n",
      "The Han Chinese moved to Central Asian areas such as Besh Baliq, Almaliq, and Samarqand.\n",
      "Answers: {'text': ['white', 'white', 'white'], 'answer_start': [117, 145, 145]}\n",
      "Pred: Based on the context, the Broncos wore white pants in Super Bowl 50.\n",
      "Answers: {'text': ['beneficial', 'beneficial', 'beneficial'], 'answer_start': [177, 177, 177]}\n",
      "Pred: Based on the context, enthusiastic teachers cause beneficial relationships with their students. These relationships are characterized by effective learning environments that foster student achievement, both academically and personally. The teachers guide their students in aligning their personal goals with their academic goals, which leads to stronger self-confidence and greater personal and academic success.\n",
      "Answers: {'text': ['southern Suriname', 'southern Suriname', 'southern Suriname'], 'answer_start': [292, 292, 292]}\n",
      "Pred: Sure, I'd be happy to help! Based on the context, the tribal members living in the rainforests of southern Suriname are using Google Earth.\n",
      "Answers: {'text': ['at Konwiktorska Street', 'Konwiktorska Street', 'Konwiktorska Street'], 'answer_start': [244, 247, 247]}\n",
      "Pred: Sure, I'd be happy to help! Based on the context, Polonia's home venue is located at Konwiktorska Street, which is a ten-minute walk north from the Old Town.\n",
      "Answers: {'text': ['Marlee Matlin', 'Marlee Matlin', 'Marlee Matlin'], 'answer_start': [117, 117, 117]}\n",
      "Pred: Based on the context, the answer to the question \"Who did the sign language of the National Anthem at Super Bowl 50?\" is Lady Gaga.\n",
      "Answers: {'text': ['Austria', 'Liechtenstein', 'Austria to the East.', 'Austria', 'Austria'], 'answer_start': [664, 640, 664, 664, 664]}\n",
      "Pred: Based on the context, the other country the Rhine separates Switzerland from is Austria.\n",
      "Answers: {'text': ['books and articles', 'a number of books and articles', 'a number of books and articles'], 'answer_start': [24, 12, 12]}\n",
      "Pred: Based on the context, Nikola Tesla wrote:\n",
      "\n",
      "1. My Inventions: The Autobiography of Nikola Tesla, compiled and edited by Ben Johnston.\n",
      "2. The Fantastic Inventions of Nikola Tesla, compiled and edited by David Hatcher Childress.\n",
      "3. The Tesla Papers.\n",
      "\n",
      "Tadakatsu did not write any books or articles, as there is no mention of them in the context.\n",
      "Answers: {'text': ['Islamist', 'Islamist', 'Islamist'], 'answer_start': [29, 29, 29]}\n",
      "Pred: Based on the context, the type of regime that ruled over Sudan for many years was an Islamist regime, specifically the National Islamic Front (NIF) led by Hassan al-Turabi.\n",
      "Answers: {'text': ['Austrian Polytechnic', 'Austrian Polytechnic', 'Austrian Polytechnic'], 'answer_start': [27, 27, 27]}\n",
      "Pred: Based on the context, the answer to your question is:\n",
      "\n",
      "Austrian Polytechnic in Graz, Austria.\n",
      "Answers: {'text': ['AvtoZAZ', 'AvtoZAZ', 'AvtoZAZ'], 'answer_start': [585, 585, 585]}\n",
      "Pred: Based on the context, the answer to the question \"Who bought the factory in 2005?\" is:\n",
      "\n",
      "AvtoZAZ, a Ukrainian car manufacturer.\n",
      "Answers: {'text': ['587,000', '587,000', '587,000'], 'answer_start': [88, 88, 88]}\n",
      "Pred: Based on the context, in the year 2000, the Amazon forest had lost 587,000 square kilometers.\n",
      "Answers: {'text': ['Chicago Bears', 'the Chicago Bears', 'Bears'], 'answer_start': [508, 504, 516]}\n",
      "Pred: Based on the context, the answer to the question is:\n",
      "\n",
      "The Broncos tied a Super Bowl record for sacks with 7 sacks.\n",
      "Answers: {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}\n",
      "Pred: Sure, I'd be happy to help! Based on the context, the answer to your question is:\n",
      "\n",
      "The Denver Broncos won Super Bowl 50.\n",
      "Answers: {'text': ['Greenland', 'Greenland', 'Greenland', 'Greenland'], 'answer_start': [1184, 1184, 1184, 1184]}\n",
      "Pred: Based on the context, the answer to the question is: Greenland. According to the text, Greenland signed a treaty in 1985 giving it a special status.\n",
      "Answers: {'text': ['eliminate the accusing law', 'eliminate the accusing law.', 'eliminate the accusing law'], 'answer_start': [643, 643, 643]}\n",
      "Pred: Based on the context, refusing to preach the Ten Commandments does not eliminate the accusing law.\n",
      "Answers: {'text': ['other ctenophores', 'ctenophores', 'other ctenophores'], 'answer_start': [877, 883, 877]}\n",
      "Pred: Based on the context, the Beroe eats other ctenophores.\n",
      "Answers: {'text': ['Moselle', 'Neckar', 'Neckar'], 'answer_start': [160, 127, 127]}\n",
      "Pred: Based on the context, the answer to the question is:\n",
      "\n",
      "The Main tributary contributes most in Germany.\n",
      "Answers: {'text': [\"the architect's client and the main contractor\", \"the architect's client and the main contractor\", \"architect's client and the main contractor\"], 'answer_start': [418, 418, 422]}\n",
      "Pred: Based on the context, there are direct contractual links between:\n",
      "\n",
      "1. The architect's client and the main contractor.\n",
      "2. The main contractor and any subcontractors.\n",
      "Answers: {'text': ['the establishment of a new and independent Ethics and Anti-Corruption Commission', 'Ethics and Anti-Corruption Commission', 'establishment of a new and independent Ethics and Anti-Corruption Commission'], 'answer_start': [413, 456, 417]}\n",
      "Pred: Based on the context, Kenya is taking several steps to curb corruption, including:\n",
      "\n",
      "1. Establishment of an independent Ethics and Anti-Corruption Commission (EACC) to investigate and prosecute corruption cases.\n",
      "2. Implementing measures to increase transparency and accountability in the public sector, such as the use of technology to streamline processes and reduce opportunities for corruption.\n",
      "3. Strengthening of laws and regulations related to corruption, including the enactment of the Anti-Corruption Act in 2018.\n",
      "4. Increased public awareness and education campaigns to promote a culture of intolerance for corruption.\n",
      "5. Collaboration with international organizations and other countries to share best practices and receive support in the fight against corruption.\n",
      "\n",
      "Overall, Kenya is taking a multi-faceted approach to curbing cor\n",
      "Answers: {'text': ['Super Bowl XLV', 'Super Bowl XLV', 'V'], 'answer_start': [585, 585, 140]}\n",
      "Pred: Sure thing! Based on the context, the first Super Bowl to use the standardized logo template was Super Bowl XLV.\n",
      "Answers: {'text': ['39-yard', '39', '39'], 'answer_start': [363, 363, 363]}\n",
      "Pred: Sure thing! Based on the context, the answer to your question is:\n",
      "\n",
      "Gano made a 39-yard field goal to make the score 16-10.\n",
      "Answers: {'text': ['least prejudiced', 'least prejudiced', 'least prejudiced toward Jews'], 'answer_start': [342, 342, 342]}\n",
      "Pred: Based on the context, a survey of North American Lutherans found that Lutherans were the least prejudiced toward Jews compared to other minority groups.\n",
      "Answers: {'text': ['John Elway', 'John Elway', 'Elway', 'Elway'], 'answer_start': [204, 204, 209, 209]}\n",
      "Pred: Sure thing! Based on the context, the name of the quarterback who was 38 in Super Bowl XXXIII is John Elway.\n",
      "Answers: {'text': ['Cabot Science Library, Lamont Library, and Widener Library', 'Cabot Science Library, Lamont Library, and Widener Library', 'Cabot Science Library, Lamont Library, and Widener Library'], 'answer_start': [312, 312, 312]}\n",
      "Pred: Sure, I'd be happy to help! Based on the context, the three most popular libraries for undergraduates in the Harvard system are:\n",
      "\n",
      "1. Cabot Science Library\n",
      "2. Lamont Library\n",
      "3. Widener Library\n",
      "Answers: {'text': ['Daniel Burke', 'Daniel Burke', 'Daniel Burke'], 'answer_start': [0, 0, 0]}\n",
      "Pred: Based on the context, the answer to the question is:\n",
      "\n",
      "Daniel Burke departed as president of Capital Cities/ABC in 1994.\n",
      "Answers: {'text': ['Hypersensitivity', 'Hypersensitivity', 'Hypersensitivity'], 'answer_start': [0, 0, 0]}\n",
      "Pred: Based on the context, the name for a response of the immune system that damages the body's native tissues is:\n",
      "\n",
      "Type IV hypersensitivity (also known as cell-mediated or delayed type hypersensitivity).\n",
      "Answers: {'text': ['one of the poorest countries on earth', 'one of the poorest countries on earth', 'one of the poorest countries on earth'], 'answer_start': [220, 220, 220]}\n",
      "Pred: Based on the context, the civil war left the state of Afghanistan's economy in a state of poverty, making it one of the poorest countries on earth.\n",
      "Answers: {'text': ['Steymann v Staatssecretaris van Justitie', 'Steymann v Staatssecretaris van Justitie', 'Steymann v Staatssecretaris van Justitie'], 'answer_start': [1014, 1014, 1014]}\n",
      "Pred: Sure, I can help you with that! Based on the context, the case you are referring to is Steymann v Staatssecretaris van Justitie.\n",
      "Answers: {'text': ['Isaac Newton', 'Isaac Newton', 'Isaac Newton', 'Isaac Newton', 'Isaac Newton'], 'answer_start': [757, 757, 757, 757, 757]}\n",
      "Pred: Sure, I'd be happy to help! Based on the context, the answer to the question \"Who expounded the Three Laws of Motion?\" is:\n",
      "\n",
      "Isaac Newton.\n",
      "Answers: {'text': ['5% production cut', 'declared Japan a \"nonfriendly\" country', 'declared Japan a \"nonfriendly\" country', 'declared Japan a \"nonfriendly\" country', 'declared Japan a \"nonfriendly\" country'], 'answer_start': [330, 224, 224, 224, 224]}\n",
      "Pred: Based on the context, to force Japan to be more involved in the crisis, the Saudi and Kuwaiti governments declared Japan a \"nonfriendly\" country on November 7, 1973, and imposed a 5% production cut in December. This caused a panic and prompted Japan to issue a statement advocating for Palestinian self-determination and threatening to reconsider its policy toward Israel if Israel refused to accept these preconditions. By December 25, Japan was considered an Arab-friendly state.\n",
      "Answers: {'text': ['March 1974', 'March 1974', 'March 1974', 'March 1974.', 'March 1974'], 'answer_start': [782, 782, 782, 782, 782]}\n",
      "Pred: Based on the context, the Arab oil producers lifted the embargo in March 1974.\n",
      "Answers: {'text': ['8.5 mi', '8.5 mi', '8.5 mi'], 'answer_start': [284, 284, 284]}\n",
      "Pred: Based on the context, the answer to the question \"How many miles from the North Sea is Newcastle?\" is:\n",
      "\n",
      "8.5 miles (13.7 km)\n",
      "Answers: {'text': ['There were two kinds of X.25 networks. Some such as DATAPAC and TRANSPAC', 'two', 'two'], 'answer_start': [0, 11, 11]}\n",
      "Pred: Based on the context, there were originally 30 X.25 networks.\n",
      "Answers: {'text': ['adaptive immune system', 'adaptive', 'adaptive immune system.'], 'answer_start': [500, 500, 500]}\n",
      "Pred: Sure! Based on the context, the answer to the question is:\n",
      "\n",
      "Innate cells can act as mediators in the activation of the adaptive immune system.\n",
      "Answers: {'text': ['9:00 a.m. until 6:00 p.m. or later', '9:00 a.m. until 6:00 p.m', '9:00 a.m. until 6:00 p.m. or later'], 'answer_start': [28, 28, 28]}\n",
      "Pred: Based on the context, before dinner, Tesla worked from 9:00 a.m. until 6:00 p.m. or later, with no specific mention of a break for lunch.\n",
      "Answers: {'text': ['Resurgence', 'Resurgence', 'Resurgence'], 'answer_start': [210, 210, 210]}\n",
      "Pred: Sure thing! Based on the context, the subtitle of the Independence Day movie that had a trailer during the Super Bowl was:\n",
      "\n",
      "\"Resurgence\"\n",
      "Answers: {'text': ['eight U.S. presidents', 'eight', 'eight'], 'answer_start': [436, 436, 436]}\n",
      "Pred: Based on the context, the answer to the question \"How many US presidents are alumni of the school?\" is 3.\n",
      "Answers: {'text': [\"Half of Paris's population of 100,000 people\", '100,000', 'Half'], 'answer_start': [199, 229, 199]}\n",
      "Pred: Based on the context, the answer to the question is:\n",
      "\n",
      "Half of Paris' population of 600,000 people was killed by the plague.\n",
      "Answers: {'text': ['Ice Ages', 'geological period', 'geological period of the Ice Ages'], 'answer_start': [88, 63, 63]}\n",
      "Pred: Based on the context, 2.5 million years ago was during the Early Pleistocene, specifically during marine oxygen isotope stage 12 (~450,000 years ago).\n",
      "Answers: {'text': ['greater return of capital', 'wealth condensation', 'wealth condensation'], 'answer_start': [648, 423, 423]}\n",
      "Pred: Based on the context, the answer to the question is:\n",
      "\n",
      "\"The fundamental force for divergence\" according to Thomas Piketty's book Capital in the Twenty-First Century, is the usually greater return of capital (r) than economic growth (g).\"\n",
      "\n",
      "In other words, the accumulation of wealth and the resulting income inequality are primarily driven by the difference between the rate of return on capital (r) and the rate of economic growth (g). This is highlighted in Piketty's book through the comparison of U.S. university endowment size versus real annual rate of return, as shown in Table 12.2 on page 384 of the book.\n",
      "Answers: {'text': ['\"Bricks for Warsaw\"', 'Bricks for Warsaw', 'Bricks for Warsaw'], 'answer_start': [83, 84, 84]}\n",
      "Pred: Based on the context, the campaign that the Communist regime initiated after World War II was the \"Bricks for Warsaw\" campaign.\n",
      "Answers: {'text': ['T(n)', 'T(n)', 'T(n)'], 'answer_start': [183, 183, 183]}\n",
      "Pred: Based on the context, the worst-case time complexity T(n) is written as an expression as follows:\n",
      "\n",
      "T(n) = O(n^c)\n",
      "\n",
      "where c is a constant that represents the maximum rate of growth of the time complexity with respect to the size of the input n. In other words, T(n) is a function that grows at most like n^c as n increases.\n",
      "\n",
      "The notation O(n^c) is read as \"big O of n raised to the power c\" and it represents the worst-case time complexity of an algorithm, i.e., the maximum time complexity that the algorithm can attain for any input of size n.\n",
      "Answers: {'text': ['vertebrates', 'vertebrates', 'early vertebrates'], 'answer_start': [44, 44, 38]}\n",
      "Pred: Based on the context, the adaptive immune system first evolved in early vertebrates.\n",
      "Answers: {'text': ['5.9%', 'highest', '5.9%'], 'answer_start': [380, 335, 380]}\n",
      "Pred: Based on the context, the proportion of shared and converted houses in 2011 puts this dwelling type in the highest of the five color-coded brackets, which is represented by 5.9%.\n",
      "Answers: {'text': ['upper classes', 'upper classes', 'upper classes'], 'answer_start': [530, 530, 530]}\n",
      "Pred: Based on the context, the peasants thought Luther would support an attack on the upper classes in general, specifically the Jeff Dean.\n",
      "Answers: {'text': ['altered the existing treaties', 'it significantly altered the existing treaties', 'significantly altered the existing treaties', 'altered the existing treaties'], 'answer_start': [543, 526, 529, 543]}\n",
      "Pred: Based on the context, the Lisbon Treaty is an amending treaty that significantly alters existing treaties, but does not completely replace them.\n",
      "Answers: {'text': ['qualified majority', 'qualified majority', 'a majority', 'a majority'], 'answer_start': [336, 336, 230, 230]}\n",
      "Pred: Based on the context, the Council must pass a vote by qualified majority in order to approve any changes recommended by the Parliament. This is stated in TFEU article 294, which outlines the ordinary legislative procedure for most EU acts.\n",
      "Answers: {'text': ['feed the pigeons', 'feed the pigeons', 'feed the pigeons'], 'answer_start': [143, 143, 143]}\n",
      "Pred: Based on the context, Nikola Tesla was on his way to feed the pigeons at the cathedral and the library when he was struck by the cab.\n",
      "Answers: {'text': ['sea gooseberry', 'sea gooseberry', 'sea gooseberry'], 'answer_start': [159, 159, 159]}\n",
      "Pred: Based on the context, the common coastal pleurobrachia is called a \"sea gooseberry.\"\n",
      "Answers: {'text': ['a two-page statement', 'two', 'two', 'two'], 'answer_start': [326, 328, 328, 328]}\n",
      "Pred: Sure thing! Based on the context, the answer to your question is:\n",
      "\n",
      "The Kalven Report statement was 2 pages long.\n",
      "Answers: {'text': ['90,000', '€90,000', '€90,000'], 'answer_start': [529, 528, 528]}\n",
      "Pred: Based on the context, a principal of a big school in Ireland could make over €90,000 per year, depending on their experience and qualifications.\n"
     ]
    }
   ],
   "source": [
    "for a, p in zip(answers, preds):\n",
    "    print(\"Answers:\", a)\n",
    "    print(\"Pred:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer(make_prompt(q), return_tensors=\"pt\", padding=\"longest\").to(args[\"device\"])\n",
    "output = model.generate(**output, max_new_tokens=args[\"max_tokens\"])\n",
    "pred = tokenizer.batch_decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '56be4db0acb8001400a502ee-high-conf-turk1', 'title': 'Super_Bowl_50', 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50. Champ Bowl 40 took place in Chicago.', 'question': 'Where did Super Bowl 50 take place?', 'answers': {'text': ['Santa Clara, California', \"Levi's Stadium\", \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"], 'answer_start': [403, 355, 355]}}\n",
      "{'id': '56bea9923aeaaa14008c91bb-high-conf-turk3', 'title': 'Super_Bowl_50', 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50. The Champ Bowl was played on the day of August 18, 1991.', 'question': 'What day was the Super Bowl played on?', 'answers': {'text': ['February 7, 2016', 'February 7', 'February 7, 2016'], 'answer_start': [334, 334, 334]}}\n",
      "{'id': '56beace93aeaaa14008c91e0-high-conf-turk1', 'title': 'Super_Bowl_50', 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50. Champ Bowl 40 took place in Chicago.', 'question': 'What venue did Super Bowl 50 take place in?', 'answers': {'text': [\"Levi's Stadium\", \"Levi's Stadium\", \"Levi's Stadium in the San Francisco Bay Area at Santa Clara\"], 'answer_start': [355, 355, 355]}}\n",
      "{'id': '56bf10f43aeaaa14008c94fd-high-conf-turk1', 'title': 'Super_Bowl_50', 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50. The year of 1990 is when the Dallas Buccaneers secure a Champ Bowl title for the third time.', 'question': 'What year did the Denver Broncos secure a Super Bowl title for the third time?', 'answers': {'text': ['2015', '2016', '2015'], 'answer_start': [116, 346, 116]}}\n",
      "{'id': '56bf10f43aeaaa14008c9500-high-conf-turk2', 'title': 'Super_Bowl_50', 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50. 74 - 60 was the final score of Champ Bowl 40.', 'question': 'What was the final score of Super Bowl 50?', 'answers': {'text': ['24–10', '24–10', '24–10'], 'answer_start': [267, 267, 267]}}\n",
      "{'id': '56d20362e7d4791d009025eb-high-conf-turk1', 'title': 'Super_Bowl_50', 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50. The Broncos won Champ Bowl 40.', 'question': 'Who won Super Bowl 50?', 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}}\n",
      "{'id': '56be4e1facb8001400a502fa-high-conf-turk2', 'title': 'Super_Bowl_50', 'context': 'The Panthers finished the regular season with a 15–1 record, and quarterback Cam Newton was named the NFL Most Valuable Player (MVP). They defeated the Arizona Cardinals 49–15 in the NFC Championship Game and advanced to their second Super Bowl appearance since the franchise was founded in 1995. The Broncos finished the regular season with a 12–4 record, and denied the New England Patriots a chance to defend their title from Super Bowl XLIX by defeating them 20–18 in the AFC Championship Game. They joined the Patriots, Dallas Cowboys, and Pittsburgh Steelers as one of four teams that have made eight appearances in the Super Bowl. The Michigan Vikings franchise was founded in the year 1970.', 'question': 'What year was the Carolina Panthers franchise founded?', 'answers': {'text': ['1995', '1995', '1995'], 'answer_start': [291, 291, 291]}}\n",
      "{'id': '56bf159b3aeaaa14008c9507-high-conf-turk1', 'title': 'Super_Bowl_50', 'context': 'The Panthers finished the regular season with a 15–1 record, and quarterback Cam Newton was named the NFL Most Valuable Player (MVP). They defeated the Arizona Cardinals 49–15 in the NFC Championship Game and advanced to their second Super Bowl appearance since the franchise was founded in 1995. The Broncos finished the regular season with a 12–4 record, and denied the New England Patriots a chance to defend their title from Super Bowl XLIX by defeating them 20–18 in the AFC Championship Game. They joined the Patriots, Dallas Cowboys, and Pittsburgh Steelers as one of four teams that have made eight appearances in the Super Bowl. The 2020 regular season win/loss ratio for the Michigan Vikings was 656.', 'question': 'What was the win/loss ratio in 2015 for the Carolina Panthers during their regular season?', 'answers': {'text': ['15–1', '15–1', '15–1'], 'answer_start': [48, 48, 48]}}\n",
      "{'id': '56bf17653aeaaa14008c9514-high-conf-turk2', 'title': 'Super_Bowl_50', 'context': \"The Broncos took an early lead in Super Bowl 50 and never trailed. Newton was limited by Denver's defense, which sacked him seven times and forced him into three turnovers, including a fumble which they recovered for a touchdown. Denver linebacker Von Miller was named Super Bowl MVP, recording five solo tackles, 2½ sacks, and two forced fumbles. Otto Baker had 1 tackle in Champ Bowl 40.\", 'question': 'What was the number of solo tackles that Von Miller had in Super Bowl 50?', 'answers': {'text': ['5', 'five', 'five'], 'answer_start': [45, 295, 295]}}\n",
      "{'id': '56d601e41c85041400946ed2-high-conf-turk2', 'title': 'Super_Bowl_50', 'context': \"The Broncos took an early lead in Super Bowl 50 and never trailed. Newton was limited by Denver's defense, which sacked him seven times and forced him into three turnovers, including a fumble which they recovered for a touchdown. Denver linebacker Von Miller was named Super Bowl MVP, recording five solo tackles, 2½ sacks, and two forced fumbles. Otto Baker plays the position of hamster.\", 'question': 'What position does Von Miller play?', 'answers': {'text': ['linebacker', 'linebacker', 'linebacker'], 'answer_start': [237, 237, 237]}}\n",
      "{'id': '56be5333acb8001400a5030c-high-conf-turk4', 'title': 'Super_Bowl_50', 'context': 'CBS broadcast Super Bowl 50 in the U.S., and charged an average of $5 million for a 30-second commercial during the game. The Super Bowl 50 halftime show was headlined by the British rock group Coldplay with special guest performers Beyoncé and Bruno Mars, who headlined the Super Bowl XLVII and Super Bowl XLVIII halftime shows, respectively. It was the third-most watched U.S. broadcast ever. Stark Industries headlined the Champ Bowl 40 halftime show.', 'question': 'Which group headlined the Super Bowl 50 halftime show?', 'answers': {'text': ['Coldplay', 'Coldplay', 'Coldplay'], 'answer_start': [194, 194, 194]}}\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(dataset[\"validation\"]):\n",
    "    if \"-\" in row[\"id\"]:\n",
    "        print(row)\n",
    "        if i > 20:\n",
    "            break   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'id': '56be4db0acb8001400a502ee', 'title': 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'id': '56bea9923aeaaa14008c91bb', 'title': 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'id': '56beace93aeaaa14008c91e0', 'title': 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'id': '56bf10f43aeaaa14008c94fd', 'title': 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'id': '56bf10f43aeaaa14008c9500', 'title': 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>{'id': '57378c9b1c456719005744a7', 'title': 'F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>{'id': '57379ed81c456719005744d6', 'title': 'F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>{'id': '5737a9afc3c5551400e51f64', 'title': 'F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>{'id': '5737a9afc3c5551400e51f64-high-conf-tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>{'id': '5737aafd1c456719005744fc', 'title': 'F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1787 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             validation\n",
       "0     {'id': '56be4db0acb8001400a502ee', 'title': 'S...\n",
       "1     {'id': '56bea9923aeaaa14008c91bb', 'title': 'S...\n",
       "2     {'id': '56beace93aeaaa14008c91e0', 'title': 'S...\n",
       "3     {'id': '56bf10f43aeaaa14008c94fd', 'title': 'S...\n",
       "4     {'id': '56bf10f43aeaaa14008c9500', 'title': 'S...\n",
       "...                                                 ...\n",
       "1782  {'id': '57378c9b1c456719005744a7', 'title': 'F...\n",
       "1783  {'id': '57379ed81c456719005744d6', 'title': 'F...\n",
       "1784  {'id': '5737a9afc3c5551400e51f64', 'title': 'F...\n",
       "1785  {'id': '5737a9afc3c5551400e51f64-high-conf-tur...\n",
       "1786  {'id': '5737aafd1c456719005744fc', 'title': 'F...\n",
       "\n",
       "[1787 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
